
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN">
<html xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      -->
      <title>Computing a sparse solution of a set of linear inequalities</title>
      <meta name="generator" content="MATLAB 7.4">
      <meta name="date" content="2007-07-21">
      <meta name="m-file" content="sparse_solution"><style>

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head>
   <body>
      <div class="content">
         <h1>Computing a sparse solution of a set of linear inequalities</h1><pre class="codeinput"><span class="comment">% Section 6.2, Boyd &amp; Vandenberghe "Convex Optimization"</span>
<span class="comment">% "Just relax: Convex programming methods for subset selection</span>
<span class="comment">%  and sparse approximation" by J. A. Tropp</span>
<span class="comment">% Written for CVX by Almir Mutapcic - 02/28/06</span>
<span class="comment">%</span>
<span class="comment">% We consider a set of linear inequalities A*x &lt;= b which are</span>
<span class="comment">% feasible. We apply two heuristics to find a sparse point x that</span>
<span class="comment">% satisfies these inequalities.</span>
<span class="comment">%</span>
<span class="comment">% The (standard) l1-norm heuristic for finding a sparse solution is:</span>
<span class="comment">%</span>
<span class="comment">%   minimize   ||x||_1</span>
<span class="comment">%       s.t.   Ax &lt;= b</span>
<span class="comment">%</span>
<span class="comment">% The log-based heuristic is an iterative method for finding</span>
<span class="comment">% a sparse solution, by finding a local optimal point for the problem:</span>
<span class="comment">%</span>
<span class="comment">%   minimize   sum(log( delta + |x_i| ))</span>
<span class="comment">%       s.t.   Ax &lt;= b</span>
<span class="comment">%</span>
<span class="comment">% where delta is a small threshold value (determines what is close to zero).</span>
<span class="comment">% We cannot solve this problem since it is a minimization of a concave</span>
<span class="comment">% function and thus it is not a convex problem. However, we can apply</span>
<span class="comment">% a heuristic in which we linearize the objective, solve, and re-iterate.</span>
<span class="comment">% This becomes a weighted l1-norm heuristic:</span>
<span class="comment">%</span>
<span class="comment">%   minimize sum( W_i * |x_i| )</span>
<span class="comment">%       s.t. Ax &lt;= b</span>
<span class="comment">%</span>
<span class="comment">% which in each iteration re-adjusts the weights W_i based on the rule:</span>
<span class="comment">%</span>
<span class="comment">%   W_i = 1/(delta + |x_i|), where delta is a small threshold value</span>
<span class="comment">%</span>
<span class="comment">% This algorithm is described in papers:</span>
<span class="comment">% "An Affine Scaling Methodology for Best Basis Selection"</span>
<span class="comment">%  by B. D. Rao and K. Kreutz-Delgado</span>
<span class="comment">% "Portfolio optimization with linear and &iuml;&not;?xed transaction costs"</span>
<span class="comment">%  by M. S. Lobo, M. Fazel, and S. Boyd</span>

<span class="comment">% fix random number generator so we can repeat the experiment</span>
seed = 0;
randn(<span class="string">'state'</span>,seed);
rand(<span class="string">'state'</span>,seed);

<span class="comment">% the threshold value below which we consider an element to be zero</span>
delta = 1e-8;

<span class="comment">% problem dimensions (m inequalities in n-dimensional space)</span>
m = 100;
n = 50;

<span class="comment">% construct a feasible set of inequalities</span>
<span class="comment">% (this system is feasible for the x0 point)</span>
A  = randn(m,n);
x0 = randn(n,1);
b  = A*x0 + rand(m,1);

<span class="comment">% l1-norm heuristic for finding a sparse solution</span>
fprintf(1, <span class="string">'Finding a sparse feasible point using l1-norm heuristic ...'</span>)
cvx_begin
  variable <span class="string">x_l1(n)</span>
  minimize( norm( x_l1, 1 ) )
  subject <span class="string">to</span>
    A*x_l1 &lt;= b;
cvx_end

<span class="comment">% number of nonzero elements in the solution (its cardinality or diversity)</span>
nnz = length(find( abs(x_l1) &gt; delta ));
fprintf(1,[<span class="string">'\nFound a feasible x in R^%d that has %d nonzeros '</span> <span class="keyword">...</span>
           <span class="string">'using the l1-norm heuristic.\n'</span>],n,nnz);

<span class="comment">% iterative log heuristic</span>
NUM_RUNS = 15;
nnzs = [];
W = ones(n,1); <span class="comment">% initial weights</span>

disp([char(10) <span class="string">'Log-based heuristic:'</span>]);
cvx_quiet(true);
<span class="keyword">for</span> k = 1:NUM_RUNS
  cvx_begin
    variable <span class="string">x_log(n)</span>
    minimize( sum( W.*abs(x_log) ) )
    subject <span class="string">to</span>
      A*x_log &lt;= b;
  cvx_end

  <span class="comment">% display new number of nonzeros in the solution vector</span>
  nnz = length(find( abs(x_log) &gt; delta ));
  nnzs = [nnzs nnz];
  fprintf(1,<span class="string">'   found a solution with %d nonzeros...\n'</span>, nnz);

  <span class="comment">% adjust the weights and re-iterate</span>
  W = 1./(delta + abs(x_log));
<span class="keyword">end</span>
cvx_quiet(false);

<span class="comment">% number of nonzero elements in the solution (its cardinality or diversity)</span>
nnz = length(find( abs(x_log) &gt; delta ));
fprintf(1,[<span class="string">'\nFound a feasible x in R^%d that has %d nonzeros '</span> <span class="keyword">...</span>
           <span class="string">'using the log heuristic.\n'</span>],n,nnz);

<span class="comment">% plot number of nonzeros versus iteration</span>
plot(1:NUM_RUNS, nnzs, [1 NUM_RUNS],[nnzs(1) nnzs(1)],<span class="string">'--'</span>);
axis([1 NUM_RUNS 0 n])
xlabel(<span class="string">'iteration'</span>), ylabel(<span class="string">'number of nonzeros (cardinality)'</span>);
legend(<span class="string">'log heuristic'</span>,<span class="string">'l1-norm heuristic'</span>,<span class="string">'Location'</span>,<span class="string">'SouthEast'</span>)
</pre><pre class="codeoutput">Finding a sparse feasible point using l1-norm heuristic ... 
Calling SDPT3: 200 variables, 100 equality constraints
------------------------------------------------------------

 num. of constraints = 100
 dim. of socp   var  = 100,   num. of socp blk  = 50
 dim. of linear var  = 100
*******************************************************************
   SDPT3: homogeneous self-dual path-following algorithms
*******************************************************************
 version  predcorr  gam  expon
    NT      1      0.000   1
it  pstep dstep p_infeas d_infeas  gap     mean(obj)    cputime
-------------------------------------------------------------------
 0  0.000 0.000 3.4e+00 5.0e+00  1.5e+02  2.500000e+01  0:0:00 chol 1  1 
 1  0.370 0.370 3.2e+00 4.7e+00  2.0e+02  4.244428e+01  0:0:00 chol 1  1 
 2  0.906 0.906 1.1e+00 1.7e+00  1.0e+02  4.124336e+01  0:0:00 chol 1  1 
 3  0.883 0.883 2.1e-01 3.1e-01  1.8e+01  3.803271e+01  0:0:00 chol 1  1 
 4  0.730 0.730 1.2e-01 1.8e-01  1.1e+01  3.606939e+01  0:0:00 chol 1  1 
 5  0.915 0.915 3.2e-02 4.6e-02  3.0e+00  3.597417e+01  0:0:00 chol 1  1 
 6  0.762 0.762 1.6e-02 2.3e-02  1.5e+00  3.597177e+01  0:0:00 chol 1  1 
 7  0.924 0.924 3.9e-03 5.7e-03  3.6e-01  3.594840e+01  0:0:00 chol 1  1 
 8  0.740 0.740 1.8e-03 2.6e-03  1.7e-01  3.594553e+01  0:0:00 chol 1  1 
 9  1.000 1.000 6.3e-04 9.2e-04  5.9e-02  3.594317e+01  0:0:00 chol 1  1 
10  0.756 0.756 2.0e-04 2.9e-04  1.8e-02  3.594176e+01  0:0:00 chol 1  1 
11  1.000 1.000 8.0e-05 1.2e-04  7.5e-03  3.594101e+01  0:0:00 chol 1  1 
12  0.809 0.809 1.6e-05 2.3e-05  1.5e-03  3.594082e+01  0:0:01 chol 1  1 
13  0.975 0.975 4.7e-06 6.9e-06  4.4e-04  3.594080e+01  0:0:01 chol 1  1 
14  0.985 0.985 9.5e-08 1.4e-07  6.6e-06  3.594078e+01  0:0:01 chol 1  1 
15  1.000 1.000 1.7e-09 2.4e-09  1.1e-07  3.594078e+01  0:0:01
  Stop: max(relative gap, infeasibilities) &lt; 1.49e-08
-------------------------------------------------------------------
 number of iterations   = 15
 primal objective value =  3.59407770e+01
 dual   objective value =  3.59407769e+01
 gap := trace(XZ)       = 1.12e-07
 relative gap           = 3.03e-09
 actual relative gap    = 7.06e-10
 rel. primal infeas     = 1.65e-09
 rel. dual   infeas     = 2.41e-09
 norm(X), norm(y), norm(Z) = 1.7e+01, 1.6e+00, 9.9e+00
 norm(A), norm(b), norm(C) = 7.3e+01, 8.8e+01, 7.1e+00
 Total CPU time (secs)  = 0.7  
 CPU time per iteration = 0.0  
 termination code       =  0
 DIMACS: 1.7e-09  0.0e+00  2.4e-09  0.0e+00  7.1e-10  1.5e-09
-------------------------------------------------------------------
------------------------------------------------------------
Status: Solved
Optimal value (cvx_optval): +35.9408

Found a feasible x in R^50 that has 44 nonzeros using the l1-norm heuristic.

Log-based heuristic:
   found a solution with 44 nonzeros...
   found a solution with 37 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...

Found a feasible x in R^50 that has 35 nonzeros using the log heuristic.
</pre><img vspace="5" hspace="5" src="sparse_solution_01.png"> <p class="footer"><br>
            Published with MATLAB&reg; 7.4<br></p>
      </div>
      <!--
##### SOURCE BEGIN #####
%% Computing a sparse solution of a set of linear inequalities

% Section 6.2, Boyd & Vandenberghe "Convex Optimization"
% "Just relax: Convex programming methods for subset selection
%  and sparse approximation" by J. A. Tropp
% Written for CVX by Almir Mutapcic - 02/28/06
%
% We consider a set of linear inequalities A*x <= b which are
% feasible. We apply two heuristics to find a sparse point x that
% satisfies these inequalities.
%
% The (standard) l1-norm heuristic for finding a sparse solution is:
%
%   minimize   ||x||_1
%       s.t.   Ax <= b
%
% The log-based heuristic is an iterative method for finding
% a sparse solution, by finding a local optimal point for the problem:
%
%   minimize   sum(log( delta + |x_i| ))
%       s.t.   Ax <= b
%
% where delta is a small threshold value (determines what is close to zero).
% We cannot solve this problem since it is a minimization of a concave
% function and thus it is not a convex problem. However, we can apply
% a heuristic in which we linearize the objective, solve, and re-iterate.
% This becomes a weighted l1-norm heuristic:
%
%   minimize sum( W_i * |x_i| )
%       s.t. Ax <= b
%
% which in each iteration re-adjusts the weights W_i based on the rule:
%
%   W_i = 1/(delta + |x_i|), where delta is a small threshold value
%
% This algorithm is described in papers:
% "An Affine Scaling Methodology for Best Basis Selection"
%  by B. D. Rao and K. Kreutz-Delgado
% "Portfolio optimization with linear and ï¬?xed transaction costs"
%  by M. S. Lobo, M. Fazel, and S. Boyd

% fix random number generator so we can repeat the experiment
seed = 0;
randn('state',seed);
rand('state',seed);

% the threshold value below which we consider an element to be zero
delta = 1e-8;

% problem dimensions (m inequalities in n-dimensional space)
m = 100;
n = 50;

% construct a feasible set of inequalities
% (this system is feasible for the x0 point)
A  = randn(m,n);
x0 = randn(n,1);
b  = A*x0 + rand(m,1); 

% l1-norm heuristic for finding a sparse solution
fprintf(1, 'Finding a sparse feasible point using l1-norm heuristic ...')
cvx_begin
  variable x_l1(n)
  minimize( norm( x_l1, 1 ) )
  subject to
    A*x_l1 <= b;
cvx_end

% number of nonzero elements in the solution (its cardinality or diversity)
nnz = length(find( abs(x_l1) > delta ));
fprintf(1,['\nFound a feasible x in R^%d that has %d nonzeros ' ...
           'using the l1-norm heuristic.\n'],n,nnz);

% iterative log heuristic
NUM_RUNS = 15;
nnzs = [];
W = ones(n,1); % initial weights

disp([char(10) 'Log-based heuristic:']);
cvx_quiet(true);
for k = 1:NUM_RUNS
  cvx_begin
    variable x_log(n)
    minimize( sum( W.*abs(x_log) ) )
    subject to
      A*x_log <= b;
  cvx_end

  % display new number of nonzeros in the solution vector
  nnz = length(find( abs(x_log) > delta ));
  nnzs = [nnzs nnz];
  fprintf(1,'   found a solution with %d nonzeros...\n', nnz);

  % adjust the weights and re-iterate
  W = 1./(delta + abs(x_log));
end
cvx_quiet(false);

% number of nonzero elements in the solution (its cardinality or diversity)
nnz = length(find( abs(x_log) > delta ));
fprintf(1,['\nFound a feasible x in R^%d that has %d nonzeros ' ...
           'using the log heuristic.\n'],n,nnz);

% plot number of nonzeros versus iteration
plot(1:NUM_RUNS, nnzs, [1 NUM_RUNS],[nnzs(1) nnzs(1)],'REPLACE_WITH_DASH_DASH');
axis([1 NUM_RUNS 0 n])
xlabel('iteration'), ylabel('number of nonzeros (cardinality)');
legend('log heuristic','l1-norm heuristic','Location','SouthEast')

##### SOURCE END #####
-->
   </body>
</html>