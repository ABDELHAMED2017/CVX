
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      --><title>Sparse covariance estimation for Gaussian variables</title><meta name="generator" content="MATLAB 7.9"><meta name="date" content="2009-11-11"><meta name="m-file" content="sparse_covariance_est_tradeoff___"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h1>Sparse covariance estimation for Gaussian variables</h1><pre class="codeinput"><span class="comment">% Jo&Atilde;&laquo;lle Skaf - 04/24/08</span>
<span class="comment">% (a figure is generated)</span>
<span class="comment">%</span>
<span class="comment">% Suppose y \in\reals^n is a Gaussian random variable with zero mean and</span>
<span class="comment">% covariance matrix R = \Expect(yy^T), with sparse inverse S = R^{-1}</span>
<span class="comment">% (S_ij = 0 means that y_i and y_j are conditionally independent).</span>
<span class="comment">% We want to estimate the covariance matrix R based on N independent</span>
<span class="comment">% samples y1,...,yN drawn from the distribution, and using prior knowledge</span>
<span class="comment">% that S is sparse</span>
<span class="comment">% A good heuristic for estimating R is to solve the problem</span>
<span class="comment">%           maximize    logdet(S) - tr(SY) - lambda*sum(sum(abs(S)))</span>
<span class="comment">%           subject to  S &gt;= 0</span>
<span class="comment">% where Y is the sample covariance of y1,...,yN, and lambda is a sparsity</span>
<span class="comment">% parameter to be chosen or tuned.</span>
<span class="comment">% A figure showing the sparsity (number of nonzeros) of S versus lambda</span>
<span class="comment">% is generated.</span>

<span class="comment">% Input data</span>
randn(<span class="string">'state'</span>,0);
n = 10;
N = 100;
Strue = sprandsym(n,0.5,0.01,1);
nnz_true = sum(Strue(:)&gt;1e-4);
R = inv(full(Strue));
y_sample = sqrtm(R)*randn(n,N);
Y = cov(y_sample');
Nlambda = 20;
lambda = logspace(-2, 3, Nlambda);
nnz = zeros(1,Nlambda);

<span class="keyword">for</span> i=1:Nlambda
    disp([<span class="string">'i = '</span> num2str(i) <span class="string">', lambda(i) = '</span> num2str(lambda(i))]);
    <span class="comment">% Maximum likelihood estimate of R^{-1}</span>
    cvx_begin <span class="string">sdp</span> <span class="string">quiet</span>
        variable <span class="string">S(n,n)</span> <span class="string">symmetric</span>
        maximize <span class="string">log_det(S)</span> <span class="string">-</span> <span class="string">trace(S*Y)</span> <span class="string">-</span> <span class="string">lambda(i)*sum(sum(abs(S)))</span>
        S &gt;= 0
    cvx_end
    nnz(i) = sum(S(:)&gt;1e-4);
<span class="keyword">end</span>

figure;
semilogx(lambda, nnz);
hold <span class="string">on</span>;
semilogx(lambda, nnz_true*ones(1,Nlambda),<span class="string">'r'</span>);
xlabel(<span class="string">'\lambda'</span>);
legend(<span class="string">'nonzeros in S'</span>, <span class="string">'nonzeros in R^{-1}'</span>);
</pre><pre class="codeoutput">i = 1, lambda(i) = 0.01
i = 2, lambda(i) = 0.01833
i = 3, lambda(i) = 0.033598
i = 4, lambda(i) = 0.061585
i = 5, lambda(i) = 0.11288
i = 6, lambda(i) = 0.20691
i = 7, lambda(i) = 0.37927
i = 8, lambda(i) = 0.69519
i = 9, lambda(i) = 1.2743
i = 10, lambda(i) = 2.3357
i = 11, lambda(i) = 4.2813
i = 12, lambda(i) = 7.8476
i = 13, lambda(i) = 14.3845
i = 14, lambda(i) = 26.3665
i = 15, lambda(i) = 48.3293
i = 16, lambda(i) = 88.5867
i = 17, lambda(i) = 162.3777
i = 18, lambda(i) = 297.6351
i = 19, lambda(i) = 545.5595
i = 20, lambda(i) = 1000
</pre><img vspace="5" hspace="5" src="sparse_covariance_est_tradeoff____01.png" alt=""> <p class="footer"><br>
      Published with MATLAB&reg; 7.9<br></p></div><!--
##### SOURCE BEGIN #####
%% Sparse covariance estimation for Gaussian variables

% JoÃ«lle Skaf - 04/24/08 
% (a figure is generated)
% 
% Suppose y \in\reals^n is a Gaussian random variable with zero mean and 
% covariance matrix R = \Expect(yy^T), with sparse inverse S = R^{-1} 
% (S_ij = 0 means that y_i and y_j are conditionally independent).
% We want to estimate the covariance matrix R based on N independent 
% samples y1,...,yN drawn from the distribution, and using prior knowledge 
% that S is sparse
% A good heuristic for estimating R is to solve the problem 
%           maximize    logdet(S) - tr(SY) - lambda*sum(sum(abs(S)))
%           subject to  S >= 0
% where Y is the sample covariance of y1,...,yN, and lambda is a sparsity
% parameter to be chosen or tuned. 
% A figure showing the sparsity (number of nonzeros) of S versus lambda 
% is generated.

% Input data 
randn('state',0);
n = 10; 
N = 100; 
Strue = sprandsym(n,0.5,0.01,1);
nnz_true = sum(Strue(:)>1e-4);
R = inv(full(Strue));
y_sample = sqrtm(R)*randn(n,N); 
Y = cov(y_sample'); 
Nlambda = 20;
lambda = logspace(-2, 3, Nlambda);
nnz = zeros(1,Nlambda);

for i=1:Nlambda
    disp(['i = ' num2str(i) ', lambda(i) = ' num2str(lambda(i))]);        
    % Maximum likelihood estimate of R^{-1}
    cvx_begin sdp quiet
        variable S(n,n) symmetric
        maximize log_det(S) - trace(S*Y) - lambda(i)*sum(sum(abs(S)))
        S >= 0
    cvx_end
    nnz(i) = sum(S(:)>1e-4);
end

figure; 
semilogx(lambda, nnz); 
hold on; 
semilogx(lambda, nnz_true*ones(1,Nlambda),'r');
xlabel('\lambda');
legend('nonzeros in S', 'nonzeros in R^{-1}');  


##### SOURCE END #####
--></body></html>