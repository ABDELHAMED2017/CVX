<html xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      -->
      <title>Figure 8.11: Approximate linear discrimination via support vector classifier</title>
      <meta name="generator" content="MATLAB 7.1">
      <meta name="date" content="2006-02-25">
      <meta name="m-file" content="svm_2"><style>

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows.  On Gecko-based browsers, the shrink-to-fit doesn't work. */ 
p,h1,h2,div.content div {
  /* for MATLAB's browser */
  width: 600px;
  /* for Mozilla, but the "width" tag overrides it anyway */
  max-width: 600px;
  /* for IE */
  width:expression(document.body.clientWidth > 620 ? "600px": "auto" );
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head>
   <body>
      <div class="content">
         <h1>Figure 8.11: Approximate linear discrimination via support vector classifier</h1><pre class="codeinput"><span class="comment">% Section 8.6.1, Boyd &amp; Vandenberghe "Convex Optimization"</span>
<span class="comment">% Original by Lieven Vandenberghe</span>
<span class="comment">% Adapted for CVX by Joelle Skaf - 10/16/05</span>
<span class="comment">% (a figure is generated)</span>
<span class="comment">%</span>
<span class="comment">% The goal is to find a function f(x) = a'*x - b that classifies the non-</span>
<span class="comment">% separable points {x_1,...,x_N} and {y_1,...,y_M} by doing a trade-off</span>
<span class="comment">% between the number of misclassifications and the width of the separating</span>
<span class="comment">% slab. a and b can be obtained by solving the following problem:</span>
<span class="comment">%           minimize    ||a||_2 + gamma*(1'*u + 1'*v)</span>
<span class="comment">%               s.t.    a'*x_i - b &gt;= 1 - u_i        for i = 1,...,N</span>
<span class="comment">%                       a'*y_i - b &lt;= -(1 - v_i)     for i = 1,...,M</span>
<span class="comment">%                       u &gt;= 0 and v &gt;= 0</span>
<span class="comment">% where gamma gives the relative weight of the number of misclassified</span>
<span class="comment">% points compared to the width of the slab.</span>

<span class="comment">% data generation</span>
n = 2;
randn(<span class="string">'state'</span>,2);
N = 50; M = 50;
Y = [1.5+0.9*randn(1,0.6*N), 1.5+0.7*randn(1,0.4*N);
     2*(randn(1,0.6*N)+1), 2*(randn(1,0.4*N)-1)];
X = [-1.5+0.9*randn(1,0.6*M),  -1.5+0.7*randn(1,0.4*M);
      2*(randn(1,0.6*M)-1), 2*(randn(1,0.4*M)+1)];
T = [-1 1; 1 1];
Y = T*Y;  X = T*X;
g = 0.1;            <span class="comment">% gamma</span>

<span class="comment">% Solution via CVX</span>
cvx_begin
    variables <span class="string">a(n)</span> <span class="string">b(1)</span> <span class="string">u(N)</span> <span class="string">v(M)</span>
    minimize (norm(a) + g*(ones(1,N)*u + ones(1,M)*v))
    X'*a - b &gt;= 1 - u;
    Y'*a - b &lt;= -(1 - v);
    u &gt;= 0;
    v &gt;= 0;
cvx_end

<span class="comment">% Displaying results</span>
linewidth = 0.5;  <span class="comment">% for the squares and circles</span>
t_min = min([X(1,:),Y(1,:)]);
t_max = max([X(1,:),Y(1,:)]);
tt = linspace(t_min-1,t_max+1,100);
p = -a(1)*tt/a(2) + b/a(2);
p1 = -a(1)*tt/a(2) + (b+1)/a(2);
p2 = -a(1)*tt/a(2) + (b-1)/a(2);

graph = plot(X(1,:),X(2,:), <span class="string">'o'</span>, Y(1,:), Y(2,:), <span class="string">'o'</span>);
set(graph(1),<span class="string">'LineWidth'</span>,linewidth);
set(graph(2),<span class="string">'LineWidth'</span>,linewidth);
set(graph(2),<span class="string">'MarkerFaceColor'</span>,[0 0.5 0]);
hold <span class="string">on</span>;
plot(tt,p, <span class="string">'-r'</span>, tt,p1, <span class="string">'--r'</span>, tt,p2, <span class="string">'--r'</span>);
axis <span class="string">equal</span>
title(<span class="string">'Approximate linear discrimination via support vector classifier'</span>);
<span class="comment">% print -deps svc-discr2.eps</span>
</pre><pre class="codeoutput"> 
Calling SeDuMi: 204 variables (1 free), 100 equality constraints
------------------------------------------------------------------------
SeDuMi 1.1 by AdvOL, 2005 and Jos F. Sturm, 1998, 2001-2003.
Alg = 2: xz-corrector, Adaptive Step-Differentiation, theta = 0.250, beta = 0.500
Split 1 free variables
eqs m = 100, order n = 205, dim = 206, blocks = 2
nnz(A) = 200 + 400, nnz(ADA) = 100, nnz(L) = 100
Handling 5 + 1 dense columns.
 it :     b*y       gap    delta  rate   t/tP*  t/tD*   feas cg cg  prec
  0 :            1.09E+000 0.000
  1 :  4.57E+000 5.25E-001 0.000 0.4840 0.9000 0.9000   2.18  1  1  1.1E+000
  2 :  4.02E+000 3.30E-001 0.000 0.6289 0.9000 0.9000   2.94  1  1  4.2E-001
  3 :  2.94E+000 1.01E-001 0.000 0.3061 0.9000 0.9000   2.18  1  1  8.9E-002
  4 :  2.45E+000 4.48E-002 0.000 0.4427 0.9000 0.9000   0.99  1  1  4.8E-002
  5 :  2.20E+000 2.20E-002 0.000 0.4906 0.9000 0.9000   0.78  1  1  2.9E-002
  6 :  2.05E+000 1.19E-002 0.000 0.5417 0.9000 0.9000   0.76  1  1  1.8E-002
  7 :  1.94E+000 5.82E-003 0.000 0.4894 0.9000 0.9000   0.85  1  1  1.0E-002
  8 :  1.88E+000 2.56E-003 0.000 0.4391 0.9000 0.9000   0.91  1  1  4.7E-003
  9 :  1.85E+000 1.09E-003 0.000 0.4273 0.9000 0.9000   0.97  1  1  2.1E-003
 10 :  1.85E+000 9.38E-006 0.000 0.0086 0.9000 0.0000   0.94  1  1  7.2E-004
 11 :  1.83E+000 1.99E-006 0.000 0.2124 0.9146 0.9000   0.99  1  1  1.5E-004
 12 :  1.83E+000 4.10E-008 0.000 0.0206 0.9900 0.9783   0.98  1  1  3.8E-006
 13 :  1.83E+000 1.25E-008 0.000 0.3051 0.9000 0.9000   1.00  1  1  1.2E-006
 14 :  1.83E+000 5.25E-009 0.000 0.4200 0.9000 0.9000   1.00  1  1  4.8E-007
 15 :  1.83E+000 1.07E-009 0.000 0.2033 0.9000 0.9000   1.00  1  1  9.8E-008
 16 :  1.83E+000 3.86E-012 0.000 0.0036 0.9990 0.9990   1.00  1  1  3.5E-010

iter seconds digits       c*x               b*y
 16      0.3   Inf  1.8257002345e+000  1.8257002346e+000
|Ax-b| =  5.8e-010, [Ay-c]_+ =  2.3E-010, |x|= 1.3e+001, |y|= 4.2e-001

Detailed timing (sec)
   Pre          IPM          Post
3.004E-002    2.604E-001    0.000E+000    
Max-norms: ||b||=1, ||c|| = 1,
Cholesky |add|=0, |skip| = 0, ||L.L|| = 1.
------------------------------------------------------------------------
Status (cvx_status): Solved
 
Optimal value (cvx_optval): 1.8257
</pre><img vspace="5" hspace="5" src="svm_2_01.png"> <p class="footer"><br>
            Published with MATLAB&reg; 7.1<br></p>
      </div>
      <!--
##### SOURCE BEGIN #####
%% Figure 8.11: Approximate linear discrimination via support vector classifier

% Section 8.6.1, Boyd & Vandenberghe "Convex Optimization"
% Original by Lieven Vandenberghe
% Adapted for CVX by Joelle Skaf - 10/16/05
% (a figure is generated)
%
% The goal is to find a function f(x) = a'*x - b that classifies the non-
% separable points {x_1,...,x_N} and {y_1,...,y_M} by doing a trade-off
% between the number of misclassifications and the width of the separating
% slab. a and b can be obtained by solving the following problem:
%           minimize    ||a||_2 + gamma*(1'*u + 1'*v)
%               s.t.    a'*x_i - b >= 1 - u_i        for i = 1,...,N
%                       a'*y_i - b <= -(1 - v_i)     for i = 1,...,M
%                       u >= 0 and v >= 0
% where gamma gives the relative weight of the number of misclassified
% points compared to the width of the slab.

% data generation
n = 2;
randn('state',2);
N = 50; M = 50;
Y = [1.5+0.9*randn(1,0.6*N), 1.5+0.7*randn(1,0.4*N);
     2*(randn(1,0.6*N)+1), 2*(randn(1,0.4*N)-1)];
X = [-1.5+0.9*randn(1,0.6*M),  -1.5+0.7*randn(1,0.4*M);
      2*(randn(1,0.6*M)-1), 2*(randn(1,0.4*M)+1)];
T = [-1 1; 1 1];
Y = T*Y;  X = T*X;
g = 0.1;            % gamma

% Solution via CVX
cvx_begin
    variables a(n) b(1) u(N) v(M)
    minimize (norm(a) + g*(ones(1,N)*u + ones(1,M)*v))
    X'*a - b >= 1 - u;
    Y'*a - b <= -(1 - v);
    u >= 0;
    v >= 0;
cvx_end

% Displaying results
linewidth = 0.5;  % for the squares and circles
t_min = min([X(1,:),Y(1,:)]);
t_max = max([X(1,:),Y(1,:)]);
tt = linspace(t_min-1,t_max+1,100);
p = -a(1)*tt/a(2) + b/a(2);
p1 = -a(1)*tt/a(2) + (b+1)/a(2);
p2 = -a(1)*tt/a(2) + (b-1)/a(2);

graph = plot(X(1,:),X(2,:), 'o', Y(1,:), Y(2,:), 'o');
set(graph(1),'LineWidth',linewidth);
set(graph(2),'LineWidth',linewidth);
set(graph(2),'MarkerFaceColor',[0 0.5 0]);
hold on;
plot(tt,p, '-r', tt,p1, 'REPLACE_WITH_DASH_DASHr', tt,p2, 'REPLACE_WITH_DASH_DASHr');
axis equal
title('Approximate linear discrimination via support vector classifier');
% print -deps svc-discr2.eps

##### SOURCE END #####
-->
   </body>
</html>