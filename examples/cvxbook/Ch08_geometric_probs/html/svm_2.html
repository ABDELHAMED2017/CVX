
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN">
<html xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      -->
      <title>Figure 8.11: Approximate linear discrimination via support vector classifier</title>
      <meta name="generator" content="MATLAB 7.4">
      <meta name="date" content="2007-06-26">
      <meta name="m-file" content="svm_2"><style>

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head>
   <body>
      <div class="content">
         <h1>Figure 8.11: Approximate linear discrimination via support vector classifier</h1><pre class="codeinput"><span class="comment">% Section 8.6.1, Boyd &amp; Vandenberghe "Convex Optimization"</span>
<span class="comment">% Original by Lieven Vandenberghe</span>
<span class="comment">% Adapted for CVX by Joelle Skaf - 10/16/05</span>
<span class="comment">% (a figure is generated)</span>
<span class="comment">%</span>
<span class="comment">% The goal is to find a function f(x) = a'*x - b that classifies the non-</span>
<span class="comment">% separable points {x_1,...,x_N} and {y_1,...,y_M} by doing a trade-off</span>
<span class="comment">% between the number of misclassifications and the width of the separating</span>
<span class="comment">% slab. a and b can be obtained by solving the following problem:</span>
<span class="comment">%           minimize    ||a||_2 + gamma*(1'*u + 1'*v)</span>
<span class="comment">%               s.t.    a'*x_i - b &gt;= 1 - u_i        for i = 1,...,N</span>
<span class="comment">%                       a'*y_i - b &lt;= -(1 - v_i)     for i = 1,...,M</span>
<span class="comment">%                       u &gt;= 0 and v &gt;= 0</span>
<span class="comment">% where gamma gives the relative weight of the number of misclassified</span>
<span class="comment">% points compared to the width of the slab.</span>

<span class="comment">% data generation</span>
n = 2;
randn(<span class="string">'state'</span>,2);
N = 50; M = 50;
Y = [1.5+0.9*randn(1,0.6*N), 1.5+0.7*randn(1,0.4*N);
     2*(randn(1,0.6*N)+1), 2*(randn(1,0.4*N)-1)];
X = [-1.5+0.9*randn(1,0.6*M),  -1.5+0.7*randn(1,0.4*M);
      2*(randn(1,0.6*M)-1), 2*(randn(1,0.4*M)+1)];
T = [-1 1; 1 1];
Y = T*Y;  X = T*X;
g = 0.1;            <span class="comment">% gamma</span>

<span class="comment">% Solution via CVX</span>
cvx_begin
    variables <span class="string">a(n)</span> <span class="string">b(1)</span> <span class="string">u(N)</span> <span class="string">v(M)</span>
    minimize (norm(a) + g*(ones(1,N)*u + ones(1,M)*v))
    X'*a - b &gt;= 1 - u;
    Y'*a - b &lt;= -(1 - v);
    u &gt;= 0;
    v &gt;= 0;
cvx_end

<span class="comment">% Displaying results</span>
linewidth = 0.5;  <span class="comment">% for the squares and circles</span>
t_min = min([X(1,:),Y(1,:)]);
t_max = max([X(1,:),Y(1,:)]);
tt = linspace(t_min-1,t_max+1,100);
p = -a(1)*tt/a(2) + b/a(2);
p1 = -a(1)*tt/a(2) + (b+1)/a(2);
p2 = -a(1)*tt/a(2) + (b-1)/a(2);

graph = plot(X(1,:),X(2,:), <span class="string">'o'</span>, Y(1,:), Y(2,:), <span class="string">'o'</span>);
set(graph(1),<span class="string">'LineWidth'</span>,linewidth);
set(graph(2),<span class="string">'LineWidth'</span>,linewidth);
set(graph(2),<span class="string">'MarkerFaceColor'</span>,[0 0.5 0]);
hold <span class="string">on</span>;
plot(tt,p, <span class="string">'-r'</span>, tt,p1, <span class="string">'--r'</span>, tt,p2, <span class="string">'--r'</span>);
axis <span class="string">equal</span>
title(<span class="string">'Approximate linear discrimination via support vector classifier'</span>);
<span class="comment">% print -deps svc-discr2.eps</span>
</pre><pre class="codeoutput"> 
Calling SDPT3: 204 variables, 100 equality constraints
------------------------------------------------------------

 num. of constraints = 100
 dim. of socp   var  =  3,   num. of socp blk  =  1
 dim. of linear var  = 200
 dim. of free   var  =  1 *** convert ublk to linear blk
*******************************************************************
   SDPT3: homogeneous self-dual path-following algorithms
*******************************************************************
 version  predcorr  gam  expon
    NT      1      0.000   1
it  pstep dstep p_infeas d_infeas  gap     mean(obj)    cputime
-------------------------------------------------------------------
 0  0.000 0.000 5.0e+00 6.8e+00  2.0e+02  5.500000e+00  0:0:00 chol  1  1
 1  0.918 0.918 3.8e+00 5.2e+00  3.4e+02  6.481339e+00  0:0:00 chol  1  1
 2  0.809 0.809 7.5e-01 1.0e+00  6.2e+01  7.654841e+00  0:0:00 chol  1  1
 3  0.766 0.766 3.5e-01 4.8e-01  2.8e+01  6.669236e+00  0:0:00 chol  1  1
 4  0.967 0.967 9.4e-02 1.3e-01  7.0e+00  3.600444e+00  0:0:00 chol  1  1
 5  0.874 0.874 1.2e-02 1.7e-02  7.9e-01  1.980838e+00  0:0:00 chol  1  1
 6  0.806 0.806 6.1e-03 8.2e-03  3.9e-01  1.915262e+00  0:0:00 chol  1  1
 7  0.791 0.791 1.6e-03 2.2e-03  1.0e-01  1.848129e+00  0:0:00 chol  1  1
 8  1.000 1.000 3.5e-04 4.7e-04  2.2e-02  1.830159e+00  0:0:00 chol  1  1
 9  0.974 0.974 1.1e-05 1.4e-05  5.7e-04  1.825828e+00  0:0:00 chol  1  1
10  0.983 0.983 3.9e-06 5.2e-06  2.5e-04  1.825744e+00  0:0:00 chol  1  1
11  0.747 0.747 1.0e-06 1.4e-06  6.5e-05  1.825712e+00  0:0:00 chol  1  1
12  1.000 1.000 3.8e-07 5.1e-07  2.4e-05  1.825705e+00  0:0:00 chol  1  1
13  1.000 1.000 3.6e-08 4.8e-08  2.2e-06  1.825701e+00  0:0:01 chol
  SWM to ill-conditioned, switch to LU factor. lu   1  1
14  1.000 1.000 1.1e-09 1.5e-09  6.1e-08  1.825700e+00  0:0:01 lu   1  1
15  1.000 1.000 8.5e-10 2.5e-11  1.1e-09  1.825700e+00  0:0:01
  Stop: max(relative gap, infeasibilities) &lt; 1.49e-08
-------------------------------------------------------------------
 number of iterations   = 15
 primal objective value =  1.82570022e+00
 dual   objective value =  1.82570022e+00
 gap := trace(XZ)       = 1.09e-09
 relative gap           = 3.85e-10
 actual relative gap    = 1.10e-10
 rel. primal infeas     = 8.52e-10
 rel. dual   infeas     = 2.49e-11
 norm(X), norm(y), norm(Z) = 1.3e+01, 4.2e-01, 1.7e+00
 norm(A), norm(b), norm(C) = 5.5e+01, 1.0e+01, 1.4e+00
 Total CPU time (secs)  = 0.6  
 CPU time per iteration = 0.0  
 termination code       =  0
 DIMACS: 8.5e-10  0.0e+00  2.5e-11  0.0e+00  1.1e-10  2.3e-10
-------------------------------------------------------------------
------------------------------------------------------------
Status: Solved
Optimal value (cvx_optval): +1.8257
</pre><img vspace="5" hspace="5" src="svm_2_01.png"> <p class="footer"><br>
            Published with MATLAB&reg; 7.4<br></p>
      </div>
      <!--
##### SOURCE BEGIN #####
%% Figure 8.11: Approximate linear discrimination via support vector classifier

% Section 8.6.1, Boyd & Vandenberghe "Convex Optimization"
% Original by Lieven Vandenberghe
% Adapted for CVX by Joelle Skaf - 10/16/05
% (a figure is generated)
%
% The goal is to find a function f(x) = a'*x - b that classifies the non-
% separable points {x_1,...,x_N} and {y_1,...,y_M} by doing a trade-off
% between the number of misclassifications and the width of the separating
% slab. a and b can be obtained by solving the following problem:
%           minimize    ||a||_2 + gamma*(1'*u + 1'*v)
%               s.t.    a'*x_i - b >= 1 - u_i        for i = 1,...,N
%                       a'*y_i - b <= -(1 - v_i)     for i = 1,...,M
%                       u >= 0 and v >= 0
% where gamma gives the relative weight of the number of misclassified
% points compared to the width of the slab.

% data generation
n = 2;
randn('state',2);
N = 50; M = 50;
Y = [1.5+0.9*randn(1,0.6*N), 1.5+0.7*randn(1,0.4*N);
     2*(randn(1,0.6*N)+1), 2*(randn(1,0.4*N)-1)];
X = [-1.5+0.9*randn(1,0.6*M),  -1.5+0.7*randn(1,0.4*M);
      2*(randn(1,0.6*M)-1), 2*(randn(1,0.4*M)+1)];
T = [-1 1; 1 1];
Y = T*Y;  X = T*X;
g = 0.1;            % gamma

% Solution via CVX
cvx_begin
    variables a(n) b(1) u(N) v(M)
    minimize (norm(a) + g*(ones(1,N)*u + ones(1,M)*v))
    X'*a - b >= 1 - u;
    Y'*a - b <= -(1 - v);
    u >= 0;
    v >= 0;
cvx_end

% Displaying results
linewidth = 0.5;  % for the squares and circles
t_min = min([X(1,:),Y(1,:)]);
t_max = max([X(1,:),Y(1,:)]);
tt = linspace(t_min-1,t_max+1,100);
p = -a(1)*tt/a(2) + b/a(2);
p1 = -a(1)*tt/a(2) + (b+1)/a(2);
p2 = -a(1)*tt/a(2) + (b-1)/a(2);

graph = plot(X(1,:),X(2,:), 'o', Y(1,:), Y(2,:), 'o');
set(graph(1),'LineWidth',linewidth);
set(graph(2),'LineWidth',linewidth);
set(graph(2),'MarkerFaceColor',[0 0.5 0]);
hold on;
plot(tt,p, '-r', tt,p1, 'REPLACE_WITH_DASH_DASHr', tt,p2, 'REPLACE_WITH_DASH_DASHr');
axis equal
title('Approximate linear discrimination via support vector classifier');
% print -deps svc-discr2.eps

##### SOURCE END #####
-->
   </body>
</html>